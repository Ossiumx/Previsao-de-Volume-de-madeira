{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ossiumx/Previsao-de-Volume-de-madeira/blob/main/Otimiza%C3%A7%C3%A3o_XGBOOSTER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ka57gAwG3OPX"
      },
      "outputs": [],
      "source": [
        "pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZlKsGM39UP-"
      },
      "outputs": [],
      "source": [
        "# Bibliotecas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, learning_curve, KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import optuna\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOaCM8QJ9iOq"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHnaBtxW3K2o"
      },
      "outputs": [],
      "source": [
        "# Carregar dados\n",
        "#dados = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/XGBoost_important_data.xlsx')\n",
        "\n",
        "dados = pd.read_excel(\"XGB.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xsxy88PL3dU0"
      },
      "outputs": [],
      "source": [
        "# Visualizar os dados\n",
        "dados.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eco5Xbgq3wfB"
      },
      "outputs": [],
      "source": [
        "# Separar as variáveis de entrada (X) e a variável de saída (y)\n",
        "x = dados.drop([\"RAIZVOL\"], axis=1)\n",
        "y = dados[\"RAIZVOL\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyV82Bb13yv1"
      },
      "outputs": [],
      "source": [
        "# Dividir os dados em conjunto de treinamento e conjunto de teste\n",
        "x_train, x_separated, y_train, y_separated = train_test_split(x, y, test_size=0.3, random_state=42)\n",
        "x_test, x_val, y_test, y_val = train_test_split(x_separated, y_separated, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gET3YNN6P38"
      },
      "outputs": [],
      "source": [
        "# Definir o modelo\n",
        "xgb_valmodel = xgb.XGBRegressor()\n",
        "xgb_valpred = cross_val_predict(xgb_valmodel, x_train, y_train, cv=5)\n",
        "xgb_valmape = np.mean(np.abs((y_train - xgb_valpred) / y_train)) * 100\n",
        "xgb_valr2 = r2_score(y_train, xgb_valpred)\n",
        "xgb_valmae = mean_absolute_error(y_train, xgb_valpred)\n",
        "xgb_valrmse = np.sqrt(mean_squared_error(y_train, xgb_valpred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0djiXjb6S5L"
      },
      "outputs": [],
      "source": [
        "print(\"XGBoost:\", \"MAPE: {:.2f}%\".format(xgb_valmape), \"R²: {:.2F}\".format(xgb_valr2), \"RMSE: {:.4f}\".format(xgb_valrmse), \"MAE: {:.4f}\".format(xgb_valmae))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1tehUEg6U47"
      },
      "outputs": [],
      "source": [
        "# Função para plotar curva de aprendizado para o mae\n",
        "\n",
        "cv = 5\n",
        "\n",
        "train_sizes=np.linspace(0.1, 1.0, 10)\n",
        "\n",
        "def plot_learning_curve(model, x, y, cv, train_sizes):\n",
        "    train_sizes, train_scores, test_scores = learning_curve(model, x, y, cv=cv, train_sizes=train_sizes, scoring='neg_mean_absolute_error')\n",
        "\n",
        "    train_mean = -np.mean(train_scores, axis=1)\n",
        "    train_std = np.std(train_scores, axis=1)\n",
        "    test_mean = -np.mean(test_scores, axis=1)\n",
        "    test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(train_sizes, train_mean, 'o-', color='r', label='Treinamento')\n",
        "    plt.plot(train_sizes, test_mean, 'o-', color='g', label='Validação')\n",
        "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='r')\n",
        "    plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color='g')\n",
        "    plt.xlabel('Tamanho do conjunto de treinamento')\n",
        "    plt.ylabel('MAE')\n",
        "    plt.title('Curva de Aprendizado para o MAE')\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBxe8SyP6X1H"
      },
      "outputs": [],
      "source": [
        "# Avaliar a curva de aprendizado do modelo\n",
        "xgb_model = xgb.XGBRegressor()\n",
        "plot_learning_curve(xgb_model, x_train, y_train, cv, train_sizes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "td9IICus6dJS"
      },
      "outputs": [],
      "source": [
        "# Função para Otimizar hiperparâmetros baseado na curva de aprenziado para a métrica MAE\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 1000, 6000),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 150),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.01, 1.0),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.01, 1.0),\n",
        "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 150),\n",
        "        \"random_state\": 42,\n",
        "    }\n",
        "    xgb_model = xgb.XGBRegressor(**params)\n",
        "\n",
        "\n",
        "    # Dividir os dados de treinamento em conjuntos de treinamento e validação\n",
        "    x_train, x_separated, y_train, y_separated = train_test_split(x, y, test_size=0.3, random_state=42)\n",
        "    x_test, x_val, y_test, y_val = train_test_split(x_separated, y_separated, test_size=0.5, random_state=42)\n",
        "\n",
        "    xgb_model.fit(x_train, y_train)\n",
        "\n",
        "    # Calcular os erros de treinamento e validação\n",
        "    y_train_pred = xgb_model.predict(x_train)\n",
        "    y_val_pred = xgb_model.predict(x_val)\n",
        "    train_error = mean_absolute_error(y_train, y_train_pred)\n",
        "    val_error = mean_absolute_error(y_val, y_val_pred)\n",
        "\n",
        "    # Calcula a diferença entre os erros de treinamento e validação\n",
        "    error_diff = abs(train_error - val_error)\n",
        "\n",
        "    # Adicionar a diferença de erro ao MAE para criar uma métrica composta\n",
        "    composite_metric = error_diff + mean_absolute_error(y_val, xgb_model.predict(x_val))\n",
        "\n",
        "    return composite_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbqFcHvy6iIj"
      },
      "outputs": [],
      "source": [
        "# Otimizar hiperparâmetros\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyQQzvSk6mCO"
      },
      "outputs": [],
      "source": [
        "# Visualizar resultados\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "print(\"  Value: \", trial.value)\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2J50H2j6od5"
      },
      "outputs": [],
      "source": [
        "xgb_model = xgb.XGBRegressor(n_estimators = 8910,learning_rate= 0.0061348615672835805, max_depth= 97, subsample= 0.6544117876474616, colsample_bytree= 0.8909681873163241, min_child_weight= 65) #0,30\n",
        "#xgb_model = xgb.XGBRegressor(n_estimators = 1956,learning_rate= 0.017987036737857547, max_depth= 12, subsample= 0.7701567055152614, colsample_bytree= 0.9996729353742191, min_child_weight= 70) #0,31\n",
        "#xgb_model = xgb.XGBRegressor(n_estimators = 3871,learning_rate= 0.01856876886536243, max_depth= 150, subsample= 0.8578916773331227, colsample_bytree= 0.8603549001123457, min_child_weight= 83)\n",
        "xgb_model.fit(x_train, y_train)\n",
        "y_pred_best = xgb_model.predict(x_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred_best)\n",
        "r2 = r2_score(y_test, y_pred_best)\n",
        "mape = np.mean(np.abs((y_test - y_pred_best) / y_test)) * 100\n",
        "mae = mean_absolute_error(y_test, y_pred_best)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred_best))\n",
        "\n",
        "print(\"XGBoost:\", \"MAPE: {:.2f}%\".format(mape), \"R²:\", r2, \"RMSE: {:.5f}\".format(rmse), \"MAE: {:.5f}\".format(mae))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYfj3VWl6r7b"
      },
      "outputs": [],
      "source": [
        "# Avaliar curva de aprendizado para o ajuste final\n",
        "plot_learning_curve(xgb_model, x_test, y_test, cv, train_sizes)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}